{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "74e35221",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import make_moons\n",
    "\n",
    "X, y = make_moons(n_samples=500, noise=0.30, random_state= 42)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25b1d2b6",
   "metadata": {},
   "source": [
    "Ensemble Learning: Voting Classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5c15d8e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VotingClassifier(estimators=[('lr', LogisticRegression(solver='liblinear')),\n",
       "                             ('rf', RandomForestClassifier(n_estimators=10)),\n",
       "                             ('svc', SVC(gamma='auto'))])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "log_clf = LogisticRegression(solver = 'liblinear')\n",
    "rnd_clf = RandomForestClassifier(n_estimators= 10)\n",
    "svm_clf = SVC(gamma = 'auto')\n",
    "\n",
    "voting_clf = VotingClassifier(\n",
    "    estimators = [('lr', log_clf),\n",
    "                 ('rf', rnd_clf),\n",
    "                 ('svc', svm_clf)],\n",
    "    voting = 'hard')\n",
    "\n",
    "voting_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fe307d6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression 0.792\n",
      "RandomForestClassifier 0.896\n",
      "SVC 0.92\n",
      "VotingClassifier 0.896\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "for clf in (log_clf, rnd_clf, svm_clf, voting_clf):\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    print(clf.__class__.__name__, accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b6e60fa8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression 0.792\n",
      "RandomForestClassifier 0.88\n",
      "SVC 0.92\n",
      "VotingClassifier 0.872\n"
     ]
    }
   ],
   "source": [
    "#soft prediction\n",
    "log_clf = LogisticRegression(solver=\"liblinear\", random_state=42)\n",
    "rnd_clf = RandomForestClassifier(n_estimators=10, random_state=42)\n",
    "svm_clf = SVC(gamma=\"auto\", probability=True, random_state=42)\n",
    "\n",
    "voting_clf = VotingClassifier(\n",
    "    estimators=[('lr', log_clf), ('rf', rnd_clf), ('svc', svm_clf)],\n",
    "    voting='soft')\n",
    "voting_clf.fit(X_train, y_train)\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "for clf in (log_clf, rnd_clf, svm_clf, voting_clf):\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    print(clf.__class__.__name__, accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4ac8501",
   "metadata": {},
   "source": [
    "Bagging and Pasting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c3ffee5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9146666666666666"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "bag_clf = BaggingClassifier(\n",
    "    DecisionTreeClassifier(), n_estimators= 500,\n",
    "    max_samples= 100, bootstrap= True, n_jobs = -1,\n",
    "    oob_score= True)\n",
    "\n",
    "bag_clf.fit(X_train, y_train)\n",
    "y_pred = bag_clf.predict(X_test)\n",
    "\n",
    "bag_clf.oob_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9a2d3982",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.896"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2362f3c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rnd_clf = RandomForestClassifier(n_estimators=500,\n",
    "                                max_leaf_nodes= 16,\n",
    "                                n_jobs= -1)\n",
    "\n",
    "rnd_clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred_rf = rnd_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d27e619c",
   "metadata": {},
   "source": [
    "Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "180ec4b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sepal length (cm) 0.10428094855987859\n",
      "sepal width (cm) 0.026415879708222866\n",
      "petal length (cm) 0.445503882177516\n",
      "petal width (cm) 0.42379928955438245\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "\n",
    "iris = load_iris()\n",
    "\n",
    "rnd_clf = RandomForestClassifier(n_estimators= 500, n_jobs = -1)\n",
    "rnd_clf.fit(iris['data'], iris['target'])\n",
    "\n",
    "for name, score in zip(iris['feature_names'], rnd_clf.feature_importances_):\n",
    "    print(name, score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32554a4d",
   "metadata": {},
   "source": [
    "### Boosting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "485e1a23",
   "metadata": {},
   "source": [
    "AdaBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8c62c20a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=1),\n",
       "                   learning_rate=0.5, n_estimators=200)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "ada_clf = AdaBoostClassifier(\n",
    "    DecisionTreeClassifier(max_depth=1), n_estimators=200,\n",
    "    algorithm= \"SAMME.R\", learning_rate=0.5)\n",
    "ada_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "153f2751",
   "metadata": {},
   "source": [
    "Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f7cf58dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Qudratic training set\n",
    "import numpy as np\n",
    "np.random.seed(42)\n",
    "X = np.random.rand(100, 1) - 0.5\n",
    "y = 3*X[:, 0]**2 + 0.05 * np.random.randn(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "78b53b98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.75026781])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#first decision tree\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "tree_reg1 = DecisionTreeRegressor(max_depth = 2)\n",
    "tree_reg1.fit(X,y)\n",
    "\n",
    "#second tree on residuals\n",
    "y2 = y - tree_reg1.predict(X)\n",
    "tree_reg2 = DecisionTreeRegressor(max_depth=2)\n",
    "tree_reg2.fit(X,y2)\n",
    "\n",
    "#second tree on the residuals\n",
    "y3 = y2 - tree_reg2.predict(X)\n",
    "tree_reg3 = DecisionTreeRegressor(max_depth=2)\n",
    "tree_reg3.fit(X,y3)\n",
    "\n",
    "\n",
    "\n",
    "X_new = np.array([[0.8]])\n",
    "y_pred = sum(tree.predict(X_new) for tree in (tree_reg1, tree_reg2, tree_reg3))\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24a51998",
   "metadata": {},
   "source": [
    "same in sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "67658f7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.75026781])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "gbrt = GradientBoostingRegressor(max_depth=2,\n",
    "                                n_estimators= 3,\n",
    "                                learning_rate= 1.0)\n",
    "gbrt.fit(X,y)\n",
    "gbrt.predict(X_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa085b63",
   "metadata": {},
   "source": [
    "Running an iterated prediction over at each level and returning optimal number of estimator based validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "50256104",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X,y)\n",
    "\n",
    "gbrt = GradientBoostingRegressor(max_depth=2, n_estimators=120)\n",
    "gbrt.fit(X_train, y_train)\n",
    "\n",
    "errors = [mean_squared_error(y_val, ypred)\n",
    "         for ypred in gbrt.staged_predict(X_val)]\n",
    "best_n_estimators = np.argmin(errors) + 1\n",
    "\n",
    "gbrt_best = GradientBoostingRegressor(max_depth=2,\n",
    "                                     n_estimators= best_n_estimators)\n",
    "gbrt_best = (X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fb3cee8",
   "metadata": {},
   "source": [
    "Early stopping when validation erron doesnot imporve for five iteratins in a row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b23d6651",
   "metadata": {},
   "outputs": [],
   "source": [
    "gbrt = GradientBoostingRegressor(max_depth= 2,\n",
    "                                warm_start= True)\n",
    "min_val_error = float(\"inf\")\n",
    "error_going_up = 0\n",
    "for n_estimators in range(1, 120):\n",
    "    gbrt.n_estimators = n_estimators\n",
    "    gbrt.fit(X_train, y_train)\n",
    "    y_pred = gbrt.predict(X_val)\n",
    "    val_error = mean_squared_error(y_val, y_pred)\n",
    "    if val_error < min_val_error:\n",
    "        min_val_error = val_error\n",
    "        error_going_up = 0\n",
    "    else:\n",
    "        error_going_up += 1\n",
    "        if error_going_up == 5:\n",
    "            break # early stopping"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e501d389",
   "metadata": {},
   "source": [
    "Stochastic Gradient Boosting\n",
    "\n",
    "at each instance tree is fitted on a random subset of training set\n",
    "\n",
    "speeds up\n",
    "\n",
    "special package xtreme gradient boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e5d37a14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting xgboost\n",
      "  Downloading xgboost-1.5.2-py3-none-win_amd64.whl (106.6 MB)\n",
      "Requirement already satisfied: scipy in c:\\users\\pk\\anaconda3\\lib\\site-packages (from xgboost) (1.7.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\pk\\anaconda3\\lib\\site-packages (from xgboost) (1.20.3)\n",
      "Installing collected packages: xgboost\n",
      "Successfully installed xgboost-1.5.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "723c8964",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "xgb_reg = xgb.XGBRegressor()\n",
    "xgb_reg.fit(X_train, y_train)\n",
    "\n",
    "y_pred = xgb_reg.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "250ddd8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-rmse:0.27669\n",
      "[1]\tvalidation_0-rmse:0.20147\n",
      "[2]\tvalidation_0-rmse:0.14687\n",
      "[3]\tvalidation_0-rmse:0.11017\n",
      "[4]\tvalidation_0-rmse:0.08607\n",
      "[5]\tvalidation_0-rmse:0.07183\n",
      "[6]\tvalidation_0-rmse:0.06386\n",
      "[7]\tvalidation_0-rmse:0.06020\n",
      "[8]\tvalidation_0-rmse:0.05896\n",
      "[9]\tvalidation_0-rmse:0.05861\n",
      "[10]\tvalidation_0-rmse:0.05889\n",
      "[11]\tvalidation_0-rmse:0.05848\n",
      "[12]\tvalidation_0-rmse:0.05867\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 0.6429717 ,  0.03401398,  0.03401398,  0.03401398, -0.01044697,\n",
       "        0.38612452,  0.28688428,  0.58283085, -0.01044697, -0.01044697,\n",
       "        0.15922701, -0.00103129,  0.6037855 , -0.00103129,  0.03401398,\n",
       "        0.12037362,  0.3806873 ,  0.10048291,  0.18836705, -0.01044697,\n",
       "       -0.01044697,  0.4506942 ,  0.3666826 , -0.01044697,  0.556862  ],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#with early stopping\n",
    "xgb_reg = xgb.XGBRegressor()\n",
    "xgb_reg.fit(X_train, y_train,\n",
    "           eval_set = [(X_val, y_val)], \n",
    "           early_stopping_rounds = 2)\n",
    "\n",
    "y_pred =xgb_reg.predict(X_val)\n",
    "y_pred"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
